{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8066e4ac-3c3a-4cd7-8df6-d4990f6b04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "573f36e8-76b7-49a9-a0fb-1586872465f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forward diffusion process\n",
    "def forward_diffusion(x0, noise, t, T):\n",
    "    alpha = 1 - (t / T)  # Simple linear schedule\n",
    "    alpha = alpha.view(-1, 1, 1, 1)  # Reshape to (batch_size, 1, 1, 1) for broadcasting\n",
    "    return alpha * x0 + (1 - alpha) * noise\n",
    "\n",
    "\n",
    "# Simple U-Net-like model for reverse process (denoising)\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset Class\n",
    "class UnderwaterImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.raw_images = sorted(os.listdir(os.path.join(root_dir, 'Train/Raw')))\n",
    "        self.reference_images = sorted(os.listdir(os.path.join(root_dir, 'Train/Reference')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_image_path = os.path.join(self.root_dir, 'Train/Raw', self.raw_images[idx])\n",
    "        reference_image_path = os.path.join(self.root_dir, 'Train/Reference', self.reference_images[idx])\n",
    "\n",
    "        raw_image = Image.open(raw_image_path).convert(\"RGB\")\n",
    "        reference_image = Image.open(reference_image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            raw_image = self.transform(raw_image)\n",
    "            reference_image = self.transform(reference_image)\n",
    "\n",
    "        return raw_image, reference_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53fa4209-11a3-41f1-b0b8-bd32f67759eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "T = 1000  # Number of time steps\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalizing to [-1, 1]\n",
    "])\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = UnderwaterImageDataset(root_dir='Dataset',transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, optimizer, loss\n",
    "model = SimpleUNet(in_channels=3, out_channels=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75405554-fc40-4f45-9f89-90b064a69a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 in Epoch 1/10, Loss: 0.21540425717830658\n",
      "Batch 1 in Epoch 1/10, Loss: 0.2042238563299179\n",
      "Batch 2 in Epoch 1/10, Loss: 0.20347857475280762\n",
      "Batch 3 in Epoch 1/10, Loss: 0.2022009640932083\n",
      "Batch 4 in Epoch 1/10, Loss: 0.21769355237483978\n",
      "Batch 5 in Epoch 1/10, Loss: 0.2031174898147583\n",
      "Batch 6 in Epoch 1/10, Loss: 0.2085644155740738\n",
      "Batch 7 in Epoch 1/10, Loss: 0.19531960785388947\n",
      "Batch 8 in Epoch 1/10, Loss: 0.1828293651342392\n",
      "Batch 9 in Epoch 1/10, Loss: 0.20270180702209473\n",
      "Batch 10 in Epoch 1/10, Loss: 0.20430169999599457\n",
      "Batch 11 in Epoch 1/10, Loss: 0.16860926151275635\n",
      "Batch 12 in Epoch 1/10, Loss: 0.19175750017166138\n",
      "Batch 13 in Epoch 1/10, Loss: 0.17395873367786407\n",
      "Batch 14 in Epoch 1/10, Loss: 0.1756550818681717\n",
      "Batch 15 in Epoch 1/10, Loss: 0.16906356811523438\n",
      "Batch 16 in Epoch 1/10, Loss: 0.1445644348859787\n",
      "Batch 17 in Epoch 1/10, Loss: 0.1587427407503128\n",
      "Batch 18 in Epoch 1/10, Loss: 0.15751734375953674\n",
      "Batch 19 in Epoch 1/10, Loss: 0.14399781823158264\n",
      "Batch 20 in Epoch 1/10, Loss: 0.18788008391857147\n",
      "Batch 21 in Epoch 1/10, Loss: 0.13145868480205536\n",
      "Batch 0 in Epoch 2/10, Loss: 0.1559203863143921\n",
      "Batch 1 in Epoch 2/10, Loss: 0.13358944654464722\n",
      "Batch 2 in Epoch 2/10, Loss: 0.14774638414382935\n",
      "Batch 3 in Epoch 2/10, Loss: 0.14950667321681976\n",
      "Batch 4 in Epoch 2/10, Loss: 0.12121029943227768\n",
      "Batch 5 in Epoch 2/10, Loss: 0.1501990705728531\n",
      "Batch 6 in Epoch 2/10, Loss: 0.1336214691400528\n",
      "Batch 7 in Epoch 2/10, Loss: 0.13432227075099945\n",
      "Batch 8 in Epoch 2/10, Loss: 0.16136667132377625\n",
      "Batch 9 in Epoch 2/10, Loss: 0.1397428661584854\n",
      "Batch 10 in Epoch 2/10, Loss: 0.12718383967876434\n",
      "Batch 11 in Epoch 2/10, Loss: 0.17109842598438263\n",
      "Batch 12 in Epoch 2/10, Loss: 0.1582266241312027\n",
      "Batch 13 in Epoch 2/10, Loss: 0.1272418349981308\n",
      "Batch 14 in Epoch 2/10, Loss: 0.13957391679286957\n",
      "Batch 15 in Epoch 2/10, Loss: 0.12754246592521667\n",
      "Batch 16 in Epoch 2/10, Loss: 0.14879821240901947\n",
      "Batch 17 in Epoch 2/10, Loss: 0.14656288921833038\n",
      "Batch 18 in Epoch 2/10, Loss: 0.14493151009082794\n",
      "Batch 19 in Epoch 2/10, Loss: 0.1401253640651703\n",
      "Batch 20 in Epoch 2/10, Loss: 0.1543647199869156\n",
      "Batch 21 in Epoch 2/10, Loss: 0.14315715432167053\n",
      "Batch 0 in Epoch 3/10, Loss: 0.1506599634885788\n",
      "Batch 1 in Epoch 3/10, Loss: 0.13871996104717255\n",
      "Batch 2 in Epoch 3/10, Loss: 0.1527596116065979\n",
      "Batch 3 in Epoch 3/10, Loss: 0.12675057351589203\n",
      "Batch 4 in Epoch 3/10, Loss: 0.13286565244197845\n",
      "Batch 5 in Epoch 3/10, Loss: 0.13629047572612762\n",
      "Batch 6 in Epoch 3/10, Loss: 0.1362701803445816\n",
      "Batch 7 in Epoch 3/10, Loss: 0.1496334671974182\n",
      "Batch 8 in Epoch 3/10, Loss: 0.11364074796438217\n",
      "Batch 9 in Epoch 3/10, Loss: 0.14122538268566132\n",
      "Batch 10 in Epoch 3/10, Loss: 0.13415710628032684\n",
      "Batch 11 in Epoch 3/10, Loss: 0.1515786051750183\n",
      "Batch 12 in Epoch 3/10, Loss: 0.13981232047080994\n",
      "Batch 13 in Epoch 3/10, Loss: 0.13810603320598602\n",
      "Batch 14 in Epoch 3/10, Loss: 0.14975996315479279\n",
      "Batch 15 in Epoch 3/10, Loss: 0.15415772795677185\n",
      "Batch 16 in Epoch 3/10, Loss: 0.1370716542005539\n",
      "Batch 17 in Epoch 3/10, Loss: 0.1206219419836998\n",
      "Batch 18 in Epoch 3/10, Loss: 0.17261594533920288\n",
      "Batch 19 in Epoch 3/10, Loss: 0.10893634706735611\n",
      "Batch 20 in Epoch 3/10, Loss: 0.13253559172153473\n",
      "Batch 21 in Epoch 3/10, Loss: 0.13057363033294678\n",
      "Batch 0 in Epoch 4/10, Loss: 0.1427464783191681\n",
      "Batch 1 in Epoch 4/10, Loss: 0.1616261750459671\n",
      "Batch 2 in Epoch 4/10, Loss: 0.12836980819702148\n",
      "Batch 3 in Epoch 4/10, Loss: 0.15369972586631775\n",
      "Batch 4 in Epoch 4/10, Loss: 0.13830450177192688\n",
      "Batch 5 in Epoch 4/10, Loss: 0.11980447173118591\n",
      "Batch 6 in Epoch 4/10, Loss: 0.12389719486236572\n",
      "Batch 7 in Epoch 4/10, Loss: 0.1406172513961792\n",
      "Batch 8 in Epoch 4/10, Loss: 0.12946341931819916\n",
      "Batch 9 in Epoch 4/10, Loss: 0.1287570297718048\n",
      "Batch 10 in Epoch 4/10, Loss: 0.14060550928115845\n",
      "Batch 11 in Epoch 4/10, Loss: 0.16300182044506073\n",
      "Batch 12 in Epoch 4/10, Loss: 0.13018184900283813\n",
      "Batch 13 in Epoch 4/10, Loss: 0.1366051882505417\n",
      "Batch 14 in Epoch 4/10, Loss: 0.15817931294441223\n",
      "Batch 15 in Epoch 4/10, Loss: 0.15355798602104187\n",
      "Batch 16 in Epoch 4/10, Loss: 0.10054420679807663\n",
      "Batch 17 in Epoch 4/10, Loss: 0.14066609740257263\n",
      "Batch 18 in Epoch 4/10, Loss: 0.12706924974918365\n",
      "Batch 19 in Epoch 4/10, Loss: 0.11644000560045242\n",
      "Batch 20 in Epoch 4/10, Loss: 0.16296173632144928\n",
      "Batch 21 in Epoch 4/10, Loss: 0.14108675718307495\n",
      "Batch 0 in Epoch 5/10, Loss: 0.12317550927400589\n",
      "Batch 1 in Epoch 5/10, Loss: 0.131431445479393\n",
      "Batch 2 in Epoch 5/10, Loss: 0.1574120670557022\n",
      "Batch 3 in Epoch 5/10, Loss: 0.11480223387479782\n",
      "Batch 4 in Epoch 5/10, Loss: 0.1319277435541153\n",
      "Batch 5 in Epoch 5/10, Loss: 0.13676150143146515\n",
      "Batch 6 in Epoch 5/10, Loss: 0.11278361082077026\n",
      "Batch 7 in Epoch 5/10, Loss: 0.12298255413770676\n",
      "Batch 8 in Epoch 5/10, Loss: 0.13945643603801727\n",
      "Batch 9 in Epoch 5/10, Loss: 0.1322314292192459\n",
      "Batch 10 in Epoch 5/10, Loss: 0.11839738488197327\n",
      "Batch 11 in Epoch 5/10, Loss: 0.14559315145015717\n",
      "Batch 12 in Epoch 5/10, Loss: 0.11604487895965576\n",
      "Batch 13 in Epoch 5/10, Loss: 0.12093684077262878\n",
      "Batch 14 in Epoch 5/10, Loss: 0.14393748342990875\n",
      "Batch 15 in Epoch 5/10, Loss: 0.12039510160684586\n",
      "Batch 16 in Epoch 5/10, Loss: 0.1146247461438179\n",
      "Batch 17 in Epoch 5/10, Loss: 0.13890205323696136\n",
      "Batch 18 in Epoch 5/10, Loss: 0.13169841468334198\n",
      "Batch 19 in Epoch 5/10, Loss: 0.13563047349452972\n",
      "Batch 20 in Epoch 5/10, Loss: 0.12781383097171783\n",
      "Batch 21 in Epoch 5/10, Loss: 0.12985385954380035\n",
      "Batch 0 in Epoch 6/10, Loss: 0.12572143971920013\n",
      "Batch 1 in Epoch 6/10, Loss: 0.1394931674003601\n",
      "Batch 2 in Epoch 6/10, Loss: 0.13019563257694244\n",
      "Batch 3 in Epoch 6/10, Loss: 0.12564997375011444\n",
      "Batch 4 in Epoch 6/10, Loss: 0.10821312665939331\n",
      "Batch 5 in Epoch 6/10, Loss: 0.12996037304401398\n",
      "Batch 6 in Epoch 6/10, Loss: 0.12513099610805511\n",
      "Batch 7 in Epoch 6/10, Loss: 0.11979057639837265\n",
      "Batch 8 in Epoch 6/10, Loss: 0.12450485676527023\n",
      "Batch 9 in Epoch 6/10, Loss: 0.152513325214386\n",
      "Batch 10 in Epoch 6/10, Loss: 0.14991401135921478\n",
      "Batch 11 in Epoch 6/10, Loss: 0.12730993330478668\n",
      "Batch 12 in Epoch 6/10, Loss: 0.16490121185779572\n",
      "Batch 13 in Epoch 6/10, Loss: 0.1518182009458542\n",
      "Batch 14 in Epoch 6/10, Loss: 0.12787050008773804\n",
      "Batch 15 in Epoch 6/10, Loss: 0.13543765246868134\n",
      "Batch 16 in Epoch 6/10, Loss: 0.10579723864793777\n",
      "Batch 17 in Epoch 6/10, Loss: 0.13450579345226288\n",
      "Batch 18 in Epoch 6/10, Loss: 0.16696001589298248\n",
      "Batch 19 in Epoch 6/10, Loss: 0.1444014459848404\n",
      "Batch 20 in Epoch 6/10, Loss: 0.11860906332731247\n",
      "Batch 21 in Epoch 6/10, Loss: 0.1271328628063202\n",
      "Batch 0 in Epoch 7/10, Loss: 0.14045076072216034\n",
      "Batch 1 in Epoch 7/10, Loss: 0.14306743443012238\n",
      "Batch 2 in Epoch 7/10, Loss: 0.12959448993206024\n",
      "Batch 3 in Epoch 7/10, Loss: 0.13550269603729248\n",
      "Batch 4 in Epoch 7/10, Loss: 0.11786221712827682\n",
      "Batch 5 in Epoch 7/10, Loss: 0.13441121578216553\n",
      "Batch 6 in Epoch 7/10, Loss: 0.12187904119491577\n",
      "Batch 7 in Epoch 7/10, Loss: 0.13132353127002716\n",
      "Batch 8 in Epoch 7/10, Loss: 0.16171568632125854\n",
      "Batch 9 in Epoch 7/10, Loss: 0.12170935422182083\n",
      "Batch 10 in Epoch 7/10, Loss: 0.11747852712869644\n",
      "Batch 11 in Epoch 7/10, Loss: 0.1272817999124527\n",
      "Batch 12 in Epoch 7/10, Loss: 0.14038030803203583\n",
      "Batch 13 in Epoch 7/10, Loss: 0.15554295480251312\n",
      "Batch 14 in Epoch 7/10, Loss: 0.15838511288166046\n",
      "Batch 15 in Epoch 7/10, Loss: 0.132917121052742\n",
      "Batch 16 in Epoch 7/10, Loss: 0.12942266464233398\n",
      "Batch 17 in Epoch 7/10, Loss: 0.12800702452659607\n",
      "Batch 18 in Epoch 7/10, Loss: 0.11240871995687485\n",
      "Batch 19 in Epoch 7/10, Loss: 0.14173521101474762\n",
      "Batch 20 in Epoch 7/10, Loss: 0.12333085387945175\n",
      "Batch 21 in Epoch 7/10, Loss: 0.1430337131023407\n",
      "Batch 0 in Epoch 8/10, Loss: 0.11419054865837097\n",
      "Batch 1 in Epoch 8/10, Loss: 0.14094260334968567\n",
      "Batch 2 in Epoch 8/10, Loss: 0.11864805221557617\n",
      "Batch 3 in Epoch 8/10, Loss: 0.11677595227956772\n",
      "Batch 4 in Epoch 8/10, Loss: 0.11519930511713028\n",
      "Batch 5 in Epoch 8/10, Loss: 0.13521146774291992\n",
      "Batch 6 in Epoch 8/10, Loss: 0.1444576531648636\n",
      "Batch 7 in Epoch 8/10, Loss: 0.13108162581920624\n",
      "Batch 8 in Epoch 8/10, Loss: 0.14934350550174713\n",
      "Batch 9 in Epoch 8/10, Loss: 0.1461065262556076\n",
      "Batch 10 in Epoch 8/10, Loss: 0.11499291658401489\n",
      "Batch 11 in Epoch 8/10, Loss: 0.16436810791492462\n",
      "Batch 12 in Epoch 8/10, Loss: 0.09930434077978134\n",
      "Batch 13 in Epoch 8/10, Loss: 0.12460679560899734\n",
      "Batch 14 in Epoch 8/10, Loss: 0.14868581295013428\n",
      "Batch 15 in Epoch 8/10, Loss: 0.13817445933818817\n",
      "Batch 16 in Epoch 8/10, Loss: 0.13776126503944397\n",
      "Batch 17 in Epoch 8/10, Loss: 0.11718308180570602\n",
      "Batch 18 in Epoch 8/10, Loss: 0.1454707384109497\n",
      "Batch 19 in Epoch 8/10, Loss: 0.1569478064775467\n",
      "Batch 20 in Epoch 8/10, Loss: 0.11812857538461685\n",
      "Batch 21 in Epoch 8/10, Loss: 0.1240338608622551\n",
      "Batch 0 in Epoch 9/10, Loss: 0.15529845654964447\n",
      "Batch 1 in Epoch 9/10, Loss: 0.16279834508895874\n",
      "Batch 2 in Epoch 9/10, Loss: 0.10901734977960587\n",
      "Batch 3 in Epoch 9/10, Loss: 0.13645216822624207\n",
      "Batch 4 in Epoch 9/10, Loss: 0.11380646377801895\n",
      "Batch 5 in Epoch 9/10, Loss: 0.12632635235786438\n",
      "Batch 6 in Epoch 9/10, Loss: 0.11685899645090103\n",
      "Batch 7 in Epoch 9/10, Loss: 0.1386207789182663\n",
      "Batch 8 in Epoch 9/10, Loss: 0.1237378939986229\n",
      "Batch 9 in Epoch 9/10, Loss: 0.11872728914022446\n",
      "Batch 10 in Epoch 9/10, Loss: 0.13478152453899384\n",
      "Batch 11 in Epoch 9/10, Loss: 0.14092426002025604\n",
      "Batch 12 in Epoch 9/10, Loss: 0.1471119374036789\n",
      "Batch 13 in Epoch 9/10, Loss: 0.12303634732961655\n",
      "Batch 14 in Epoch 9/10, Loss: 0.13748770952224731\n",
      "Batch 15 in Epoch 9/10, Loss: 0.12954948842525482\n",
      "Batch 16 in Epoch 9/10, Loss: 0.11269891262054443\n",
      "Batch 17 in Epoch 9/10, Loss: 0.12875619530677795\n",
      "Batch 18 in Epoch 9/10, Loss: 0.11466505378484726\n",
      "Batch 19 in Epoch 9/10, Loss: 0.14080539345741272\n",
      "Batch 20 in Epoch 9/10, Loss: 0.14764522016048431\n",
      "Batch 21 in Epoch 9/10, Loss: 0.1311529278755188\n",
      "Batch 0 in Epoch 10/10, Loss: 0.13303972780704498\n",
      "Batch 1 in Epoch 10/10, Loss: 0.13528192043304443\n",
      "Batch 2 in Epoch 10/10, Loss: 0.11493388563394547\n",
      "Batch 3 in Epoch 10/10, Loss: 0.14255523681640625\n",
      "Batch 4 in Epoch 10/10, Loss: 0.14935903251171112\n",
      "Batch 5 in Epoch 10/10, Loss: 0.13722571730613708\n",
      "Batch 6 in Epoch 10/10, Loss: 0.13631631433963776\n",
      "Batch 7 in Epoch 10/10, Loss: 0.15948711335659027\n",
      "Batch 8 in Epoch 10/10, Loss: 0.16243386268615723\n",
      "Batch 9 in Epoch 10/10, Loss: 0.14075106382369995\n",
      "Batch 10 in Epoch 10/10, Loss: 0.11669271439313889\n",
      "Batch 11 in Epoch 10/10, Loss: 0.12178385257720947\n",
      "Batch 12 in Epoch 10/10, Loss: 0.1376730352640152\n",
      "Batch 13 in Epoch 10/10, Loss: 0.11478472501039505\n",
      "Batch 14 in Epoch 10/10, Loss: 0.13606761395931244\n",
      "Batch 15 in Epoch 10/10, Loss: 0.10740387439727783\n",
      "Batch 16 in Epoch 10/10, Loss: 0.12605568766593933\n",
      "Batch 17 in Epoch 10/10, Loss: 0.10926753282546997\n",
      "Batch 18 in Epoch 10/10, Loss: 0.14647053182125092\n",
      "Batch 19 in Epoch 10/10, Loss: 0.12260735780000687\n",
      "Batch 20 in Epoch 10/10, Loss: 0.12793472409248352\n",
      "Batch 21 in Epoch 10/10, Loss: 0.14212356507778168\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (raw_images, ref_images) in enumerate(train_loader):\n",
    "        raw_images, ref_images = raw_images.to(device), ref_images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Apply forward diffusion (add noise)\n",
    "        noise = torch.randn_like(raw_images)\n",
    "        t = torch.randint(0, T, (raw_images.shape[0],)).to(device)  # Random time steps\n",
    "        xt = forward_diffusion(raw_images, noise, t, T)\n",
    "        \n",
    "        # Denoising step: predict original image from noisy image\n",
    "        reconstructed = model(xt)\n",
    "        loss = criterion(reconstructed, ref_images)  # Compare to reference image\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Batch {batch_idx} in Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4535381b-44fc-49ff-9678-ffb8170bb50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# MSE Calculation\n",
    "def mse(image1, image2):\n",
    "    return F.mse_loss(image1, image2)\n",
    "\n",
    "# PSNR Calculation\n",
    "def psnr(image1, image2, max_val=1.0):\n",
    "    mse_value = mse(image1, image2)\n",
    "    psnr_value = 10 * torch.log10(max_val ** 2 / mse_value)\n",
    "    return psnr_value\n",
    "\n",
    "# SSIM Calculation\n",
    "def ssim(image1, image2, C1=0.01**2, C2=0.03**2):\n",
    "    mu1 = F.avg_pool2d(image1, kernel_size=11, stride=1, padding=5)\n",
    "    mu2 = F.avg_pool2d(image2, kernel_size=11, stride=1, padding=5)\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(image1 ** 2, kernel_size=11, stride=1, padding=5) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(image2 ** 2, kernel_size=11, stride=1, padding=5) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(image1 * image2, kernel_size=11, stride=1, padding=5) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea1b4649-7c89-43de-9c9c-f2f18c2d5721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.025100612721258873\n",
      "Mean PSNR: 17.150235718174983\n",
      "Mean SSIM: 0.6281609176805145\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the custom dataset\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, raw_dir, reference_dir, transform=None):\n",
    "        self.raw_dir = raw_dir\n",
    "        self.reference_dir = reference_dir\n",
    "        self.transform = transform\n",
    "        self.image_filenames = os.listdir(raw_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_filenames[idx]\n",
    "        raw_image_path = os.path.join(self.raw_dir, image_filename)\n",
    "        reference_image_path = os.path.join(self.reference_dir, image_filename)\n",
    "\n",
    "        raw_image = Image.open(raw_image_path).convert('RGB')\n",
    "        reference_image = Image.open(reference_image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            raw_image = self.transform(raw_image)\n",
    "            reference_image = self.transform(reference_image)\n",
    "\n",
    "        return raw_image, reference_image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "raw_dir = 'Dataset/Test/Raw'\n",
    "reference_dir = 'Dataset/Test/Reference'\n",
    "test_dataset = PairedImageDataset(raw_dir, reference_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set the generator to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize accumulators for MSE, PSNR, SSIM\n",
    "mse_total = 0.0\n",
    "psnr_total = 0.0\n",
    "ssim_total = 0.0\n",
    "num_samples = len(test_loader)\n",
    "\n",
    "for raw_image, reference_image in test_loader:\n",
    "    with torch.no_grad():\n",
    "        generated_image = model(raw_image)\n",
    "\n",
    "    generated_image = (generated_image + 1) / 2\n",
    "    reference_image = (reference_image + 1) / 2\n",
    "\n",
    "    # Calculate MSE, PSNR, SSIM for this pair\n",
    "    mse_value = mse(generated_image, reference_image)\n",
    "    psnr_value = psnr(generated_image, reference_image)\n",
    "    ssim_value = ssim(generated_image, reference_image)\n",
    "\n",
    "    mse_total += mse_value.item()\n",
    "    psnr_total += psnr_value.item()\n",
    "    ssim_total += ssim_value.item()\n",
    "\n",
    "mean_mse = mse_total / num_samples\n",
    "mean_psnr = psnr_total / num_samples\n",
    "mean_ssim = ssim_total / num_samples\n",
    "\n",
    "print(f\"Mean MSE: {mean_mse}\")\n",
    "print(f\"Mean PSNR: {mean_psnr}\")\n",
    "print(f\"Mean SSIM: {mean_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b0843-e148-4c1a-919f-23757480f722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
